"""
Pseudo-Label Management for WSI-level Classification with Attention Scores.

This module handles loading and processing attention scores (.pt files) for WSI patches,
supporting both binary (single-channel) and multi-class modes. It provides utilities to
select high-confidence patches based on attention scores, enabling the "Selection-then-Prompting"
strategy described in the WSI adaptation framework.

Structure:
- .pt files contain attention scores for each patch coordinate in a WSI
- Binary mode: single attention value per coordinate
  * Class 0 confidence = 1 - score (inverse relationship)
  * Class 1 confidence = score (direct relationship)
- Multi-class mode: one attention score per class per coordinate

Per-Class Thresholds:
- Confidence thresholds can be specified per-class for fine-grained control
- Useful when different classes have different confidence requirements
- Can be provided as: float (single), list [class0, class1, ...], or dict {class_id: threshold}
- Example: {0: 0.90, 1: 0.995} means 90% threshold for class 0, 99.5% for class 1

Usage:
    loader = PseudoLabelLoader(pseudo_label_dir, binary_mode=True, num_classes=2)
    scores = loader.load_wsi_scores(wsi_name)  # shape: (num_patches,) or (num_patches, num_classes)
    selector = PatchSelector(num_classes, selection_strategy='percentile')
    
    # Single threshold
    mask = selector.select_patches(scores, confidence_threshold=0.8, binary_mode=True)
    
    # Per-class thresholds
    mask = selector.select_patches(
        scores, 
        confidence_threshold={0: 0.90, 1: 0.995},  # Different thresholds per class
        binary_mode=True
    )
"""

import torch
import numpy as np
from pathlib import Path
from typing import Optional, Dict, Tuple, List, Union
import os
from .wsi_common import (
    compute_entropy,
    compute_margin,
    get_statistics_dict,
    compute_confidence_from_scores,
)


class PseudoLabelLoader:
    """
    Load and parse attention scores from .pt files for WSI patches.
    
    Supports two modes:
    1. Binary: Single attention channel (low values = class 0, high values = class 1)
    2. Multi-class: Multiple attention channels (one per class)
    
    Args:
        pseudo_label_dir: Directory containing .pt files with attention scores
        binary_mode: If True, interpret single-channel scores as binary classification
        num_classes: Number of classes (used in multi-class mode)
        file_suffix: Expected file extension for pseudo-label files
    """
    
    def __init__(
        self,
        pseudo_label_dir: str,
        binary_mode: bool = True,
        num_classes: int = 2,
        file_suffix: str = ".pt"
    ):
        self.pseudo_label_dir = Path(pseudo_label_dir)
        self.binary_mode = binary_mode
        self.num_classes = num_classes
        self.file_suffix = file_suffix
        
        if not self.pseudo_label_dir.exists():
            raise FileNotFoundError(f"Pseudo-label directory not found: {pseudo_label_dir}")
    
    def load_wsi_scores(self, wsi_name: str) -> torch.Tensor:
        """
        Load attention scores for a WSI.
        
        Args:
            wsi_name: Name of WSI (without extension, or with .pt)
            
        Returns:
            Tensor of shape (num_patches,) for binary mode or (num_patches, num_classes) for multi-class
            
        Raises:
            FileNotFoundError: If the corresponding .pt file doesn't exist
        """
        # Handle both with and without extension
        if not wsi_name.endswith(self.file_suffix):
            wsi_name = wsi_name + self.file_suffix
        
        pt_path = self.pseudo_label_dir / wsi_name
        
        if not pt_path.exists():
            raise FileNotFoundError(f"Pseudo-label file not found: {pt_path}")
        
        # Load with weights_only=False to support numpy arrays (PyTorch 2.6+)
        # These are trusted pseudo-label files generated by our own MIL model
        data = torch.load(pt_path, map_location='cpu', weights_only=False)
        
        # Handle different data formats
        if isinstance(data, dict):
            # If it's a dict, try common keys for attention scores
            if 'patch_logits' in data:
                scores = data['patch_logits']
            elif 'attention_scores' in data:
                scores = data['attention_scores']
            elif 'scores' in data:
                scores = data['scores']
            elif 'attention' in data:
                scores = data['attention']
            elif 'predictions' in data:
                scores = data['predictions']
            else:
                # Try to find any tensor in the dict
                tensor_keys = [k for k, v in data.items() if isinstance(v, (torch.Tensor, np.ndarray))]
                if len(tensor_keys) == 1:
                    scores = data[tensor_keys[0]]
                elif len(tensor_keys) > 1:
                    raise ValueError(
                        f"Multiple tensors found in {pt_path}: {tensor_keys}. "
                        f"Please specify which key contains attention scores. "
                        f"Common keys: 'patch_logits', 'attention_scores', 'scores'"
                    )
                else:
                    raise ValueError(f"No tensor/array found in dict loaded from {pt_path}. Keys: {list(data.keys())}")
        elif isinstance(data, torch.Tensor):
            scores = data
        elif isinstance(data, np.ndarray):
            scores = data
        else:
            raise ValueError(f"Unexpected data type {type(data)} in {pt_path}")
        
        # Convert to tensor if numpy array
        if isinstance(scores, np.ndarray):
            scores = torch.from_numpy(scores)
        
        # Validate shape and format
        if scores.dim() == 1:
            # Binary or single-class scores: (num_patches,)
            if not self.binary_mode and self.num_classes > 1:
                # If expecting multi-class but got single channel, expand it
                print(f"Warning: Expected multi-class scores but got single channel for {wsi_name}")
        elif scores.dim() == 2:
            # Multi-class scores: (num_patches, num_classes)
            if scores.shape[1] != self.num_classes:
                raise ValueError(
                    f"Shape mismatch: Expected {self.num_classes} classes but got {scores.shape[1]} "
                    f"in {pt_path}. Shape is {scores.shape}"
                )
        else:
            raise ValueError(f"Unexpected tensor shape {scores.shape} in {pt_path}")
        
        return scores
    
    def get_all_wsi_names(self) -> List[str]:
        """Get list of all WSI names available in pseudo-label directory."""
        pt_files = list(self.pseudo_label_dir.glob(f"*{self.file_suffix}"))
        return [f.stem for f in pt_files]
    
    def validate_mode_consistency(self) -> Tuple[bool, str]:
        """
        Validate that all .pt files are consistent with configured mode.
        
        Returns:
            (is_valid, message) tuple
        """
        wsi_names = self.get_all_wsi_names()
        if not wsi_names:
            return False, "No pseudo-label files found"
        
        for wsi_name in wsi_names[:5]:  # Check first 5 files
            try:
                scores = self.load_wsi_scores(wsi_name)
                if self.binary_mode and scores.dim() == 2:
                    if scores.shape[1] != 1:
                        return False, f"Binary mode expects 1 channel, got {scores.shape[1]}"
                elif not self.binary_mode and scores.dim() == 1:
                    return False, f"Multi-class mode expects 2D tensor, got 1D"
            except Exception as e:
                return False, f"Error loading {wsi_name}: {str(e)}"
        
        return True, "All checked files are consistent with configured mode"


class PatchSelector:
    """
    Select high-confidence patches from WSI based on attention scores.
    
    Implements multiple selection strategies:
    - 'percentile': Select patches in top percentile
    - 'threshold': Select patches above absolute threshold
    - 'entropy': Select patches with lowest entropy (most confident predictions)
    - 'margin': Select patches with largest margin between top-2 class scores
    
    Args:
        num_classes: Number of classes
        selection_strategy: Strategy for selecting patches
        device: Device for computation
    """
    
    def __init__(
        self,
        num_classes: int = 2,
        selection_strategy: str = 'percentile',
        device: str = 'cpu'
    ):
        self.num_classes = num_classes
        self.selection_strategy = selection_strategy
        self.device = device
        
        valid_strategies = ['percentile', 'threshold', 'entropy', 'margin']
        if selection_strategy not in valid_strategies:
            raise ValueError(f"Unknown selection strategy: {selection_strategy}. "
                           f"Valid options: {valid_strategies}")
    
    def _convert_binary_to_multiclass(self, scores: torch.Tensor) -> torch.Tensor:
        """
        Convert binary scores to multi-class format.
        In binary mode: class 0 confidence = 1 - scores, class 1 confidence = scores
        
        Args:
            scores: 1D tensor of shape (num_patches,)
            
        Returns:
            2D tensor of shape (num_patches, 2) with [class_0_conf, class_1_conf]
        """
        if scores.dim() != 1:
            return scores
        
        class_1_conf = scores
        class_0_conf = 1 - scores
        return torch.stack([class_0_conf, class_1_conf], dim=1)
    
    def _parse_threshold(self, threshold: Union[float, List[float], Dict[int, float]], 
                        target_class: Optional[int] = None) -> Union[float, torch.Tensor]:
        """
        Parse confidence threshold parameter into appropriate format.
        
        Args:
            threshold: Single value, list, or dict of thresholds
            target_class: If specified, return threshold for this class only
            
        Returns:
            Float threshold or tensor of per-class thresholds
        """
        if isinstance(threshold, dict):
            if target_class is not None:
                return threshold.get(target_class, 0.8)
            # Convert dict to tensor
            thresholds = torch.zeros(self.num_classes, device=self.device)
            for class_id, thresh in threshold.items():
                if 0 <= class_id < self.num_classes:
                    thresholds[class_id] = thresh
            return thresholds
        elif isinstance(threshold, (list, tuple)):
            if len(threshold) != self.num_classes:
                raise ValueError(f"Threshold list length {len(threshold)} != num_classes {self.num_classes}")
            if target_class is not None:
                return threshold[target_class]
            return torch.tensor(threshold, device=self.device)
        else:
            # Single float value
            return float(threshold)
    
    def select_patches(
        self,
        scores: torch.Tensor,
        confidence_threshold: Union[float, List[float], Dict[int, float]] = 0.8,
        target_class: Optional[int] = None,
        binary_mode: bool = False,
        return_scores: bool = False
    ) -> Union[np.ndarray, Tuple[np.ndarray, torch.Tensor]]:
        """
        Select high-confidence patches based on attention scores.
        
        Args:
            scores: Attention scores, shape (num_patches,) or (num_patches, num_classes)
            confidence_threshold: Threshold for selection (interpretation depends on strategy)
                - float: Single threshold applied to all classes
                - List[float]: Per-class thresholds (length must match num_classes)
                - Dict[int, float]: Per-class thresholds mapping class_id -> threshold
            target_class: If specified, select patches confident for this specific class only
            binary_mode: If True and scores are 1D, treat as binary classification where
                class 0 confidence = 1 - scores, class 1 confidence = scores
            return_scores: If True, also return the confidence scores for selected patches
            
        Returns:
            Boolean mask of selected patches, shape (num_patches,)
            If return_scores=True, also returns confidence scores
        """
        scores = scores.to(self.device)
        
        if self.selection_strategy == 'percentile':
            return self._select_by_percentile(scores, confidence_threshold, target_class, binary_mode, return_scores)
        elif self.selection_strategy == 'threshold':
            return self._select_by_threshold(scores, confidence_threshold, target_class, binary_mode, return_scores)
        elif self.selection_strategy == 'entropy':
            return self._select_by_entropy(scores, confidence_threshold, target_class, binary_mode, return_scores)
        elif self.selection_strategy == 'margin':
            return self._select_by_margin(scores, confidence_threshold, target_class, binary_mode, return_scores)
    
    def _select_by_percentile(
        self,
        scores: torch.Tensor,
        percentile: Union[float, List[float], Dict[int, float]],
        target_class: Optional[int],
        binary_mode: bool,
        return_scores: bool
    ) -> Union[np.ndarray, Tuple[np.ndarray, torch.Tensor]]:
        """Select patches in top percentile by confidence."""
        # Convert binary scores to multi-class if needed
        if scores.dim() == 1 and binary_mode:
            scores = self._convert_binary_to_multiclass(scores)
        
        if target_class is not None:
            # Select for specific class
            if scores.dim() == 1:
                confidence = scores
            else:
                confidence = scores[:, target_class]
            
            thresh_val = self._parse_threshold(percentile, target_class)
            threshold = torch.quantile(confidence, thresh_val)
            mask = (confidence >= threshold).cpu().numpy()
        else:
            # Select across all classes
            if scores.dim() == 1:
                confidence = scores
                thresh_val = self._parse_threshold(percentile, None)
                if isinstance(thresh_val, torch.Tensor):
                    thresh_val = thresh_val.mean()  # Average for single-class case
                threshold = torch.quantile(confidence, thresh_val)
                mask = (confidence >= threshold).cpu().numpy()
            else:
                # Multi-class: check per-class thresholds
                parsed_thresh = self._parse_threshold(percentile, None)
                if isinstance(parsed_thresh, float):
                    # Single threshold - use max confidence
                    confidence = scores.max(dim=1)[0]
                    threshold = torch.quantile(confidence, parsed_thresh)
                    mask = (confidence >= threshold).cpu().numpy()
                else:
                    # Per-class thresholds - patch selected if any class exceeds its threshold
                    mask = torch.zeros(scores.shape[0], dtype=torch.bool, device=self.device)
                    confidence_list = []
                    for class_id in range(self.num_classes):
                        class_scores = scores[:, class_id]
                        class_thresh = torch.quantile(class_scores, parsed_thresh[class_id])
                        class_mask = class_scores >= class_thresh
                        mask = mask | class_mask
                        confidence_list.append(class_scores)
                    mask = mask.cpu().numpy()
                    confidence = torch.stack(confidence_list, dim=1).max(dim=1)[0]
        
        if return_scores:
            return mask, confidence[mask]
        return mask
    
    def _select_by_threshold(
        self,
        scores: torch.Tensor,
        threshold: Union[float, List[float], Dict[int, float]],
        target_class: Optional[int],
        binary_mode: bool,
        return_scores: bool
    ) -> Union[np.ndarray, Tuple[np.ndarray, torch.Tensor]]:
        """Select patches with confidence above absolute threshold."""
        # Convert binary scores to multi-class if needed
        if scores.dim() == 1 and binary_mode:
            scores = self._convert_binary_to_multiclass(scores)
        
        if target_class is not None:
            # Select for specific class
            if scores.dim() == 1:
                confidence = scores
            else:
                confidence = scores[:, target_class]
            
            thresh_val = self._parse_threshold(threshold, target_class)
            mask = (confidence >= thresh_val).cpu().numpy()
        else:
            # Select across all classes
            if scores.dim() == 1:
                confidence = scores
                thresh_val = self._parse_threshold(threshold, None)
                if isinstance(thresh_val, torch.Tensor):
                    thresh_val = thresh_val.mean()  # Average for single-class case
                mask = (confidence >= thresh_val).cpu().numpy()
            else:
                # Multi-class: check per-class thresholds
                parsed_thresh = self._parse_threshold(threshold, None)
                if isinstance(parsed_thresh, float):
                    # Single threshold - use max confidence
                    confidence = scores.max(dim=1)[0]
                    mask = (confidence >= parsed_thresh).cpu().numpy()
                else:
                    # Per-class thresholds - patch selected if any class exceeds its threshold
                    mask = torch.zeros(scores.shape[0], dtype=torch.bool, device=self.device)
                    confidence_list = []
                    for class_id in range(self.num_classes):
                        class_scores = scores[:, class_id]
                        class_mask = class_scores >= parsed_thresh[class_id]
                        mask = mask | class_mask
                        confidence_list.append(class_scores)
                    mask = mask.cpu().numpy()
                    confidence = torch.stack(confidence_list, dim=1).max(dim=1)[0]
        
        if return_scores:
            return mask, confidence[mask]
        return mask
    
    def _select_by_entropy(
        self,
        scores: torch.Tensor,
        entropy_threshold: Union[float, List[float], Dict[int, float]],
        target_class: Optional[int],
        binary_mode: bool,
        return_scores: bool
    ) -> Union[np.ndarray, Tuple[np.ndarray, torch.Tensor]]:
        """Select patches with entropy below threshold (most confident predictions)."""
        # Convert binary scores to multi-class if needed
        if scores.dim() == 1 and binary_mode:
            scores = self._convert_binary_to_multiclass(scores)
        
        if scores.dim() == 1:
            # For binary scores, convert to probabilities (assuming sigmoid)
            prob_class1 = torch.sigmoid(scores)
            prob_class0 = 1 - prob_class1
            probs = torch.stack([prob_class0, prob_class1], dim=1)
        else:
            # Multi-class: use softmax to get probabilities
            probs = torch.softmax(scores, dim=1)
        
        # Compute entropy using shared utility
        entropy = compute_entropy(probs, dim=1)
        
        # Note: entropy threshold is global (not per-class) as it's a measure of overall uncertainty
        thresh_val = self._parse_threshold(entropy_threshold, target_class)
        if isinstance(thresh_val, torch.Tensor):
            thresh_val = thresh_val.mean()  # Average if per-class provided
        
        # Lower entropy threshold means select more confident predictions
        mask = (entropy <= thresh_val).cpu().numpy()
        confidence = 1 - (entropy / np.log(self.num_classes))  # Normalized confidence
        
        if return_scores:
            return mask, confidence[mask]
        return mask
    
    def _select_by_margin(
        self,
        scores: torch.Tensor,
        margin_threshold: Union[float, List[float], Dict[int, float]],
        target_class: Optional[int],
        binary_mode: bool,
        return_scores: bool
    ) -> Union[np.ndarray, Tuple[np.ndarray, torch.Tensor]]:
        """Select patches where margin between top-2 classes exceeds threshold."""
        # Convert binary scores to multi-class if needed
        if scores.dim() == 1 and binary_mode:
            scores = self._convert_binary_to_multiclass(scores)
        
        if scores.dim() == 1 and self.num_classes > 2:
            raise ValueError("Margin strategy requires multi-class scores for >2 classes")
        
        # Use shared margin computation
        margin = compute_margin(scores)
        
        # Note: margin threshold is global (not per-class)
        thresh_val = self._parse_threshold(margin_threshold, target_class)
        if isinstance(thresh_val, torch.Tensor):
            thresh_val = thresh_val.mean()  # Average if per-class provided
        
        mask = (margin >= thresh_val).cpu().numpy()
        
        if return_scores:
            return mask, margin[mask]
        return mask
    
    def select_patches_per_class(
        self,
        scores: torch.Tensor,
        confidence_threshold: float = 0.8,
        return_indices: bool = False
    ) -> Dict[int, Union[np.ndarray, np.ndarray]]:
        """
        Select high-confidence patches for each class separately.
        
        Useful for building class-specific prototype banks.
        
        Args:
            scores: Shape (num_patches, num_classes) - multi-class mode required
            confidence_threshold: Confidence threshold
            return_indices: If True, return indices instead of boolean masks
            
        Returns:
            Dictionary mapping class_id -> (indices or mask) of selected patches
        """
        if scores.dim() == 1:
            raise ValueError("Per-class selection requires multi-class scores (2D tensor)")
        
        result = {}
        for class_id in range(scores.shape[1]):
            class_scores = scores[:, class_id]
            mask = self._select_by_threshold(class_scores.unsqueeze(1), confidence_threshold, False)
            
            if return_indices:
                result[class_id] = np.where(mask)[0]
            else:
                result[class_id] = mask
        
        return result


class PseudoLabelAnalyzer:
    """
    Analyze pseudo-label quality and statistics across dataset.
    
    Useful for understanding attention score distribution and selecting
    appropriate confidence thresholds.
    """
    
    def __init__(self, loader: PseudoLabelLoader):
        self.loader = loader
    
    def analyze_all_wsis(self) -> Dict:
        """Compute statistics across all WSI pseudo-labels."""
        wsi_names = self.loader.get_all_wsi_names()
        
        all_scores = []
        stats = {
            'num_wsis': len(wsi_names),
            'per_wsi_stats': {},
            'global_stats': {}
        }
        
        for wsi_name in wsi_names:
            scores = self.loader.load_wsi_scores(wsi_name)
            all_scores.append(scores)
            
            # Per-WSI statistics
            if scores.dim() == 1:
                stats['per_wsi_stats'][wsi_name] = {
                    'num_patches': scores.shape[0],
                    **get_statistics_dict(scores),
                }
            else:
                # Per-class statistics for multi-class
                stats['per_wsi_stats'][wsi_name] = {
                    'num_patches': scores.shape[0],
                    'num_classes': scores.shape[1],
                }
                for class_id in range(scores.shape[1]):
                    class_scores = scores[:, class_id]
                    stats_dict = get_statistics_dict(class_scores)
                    # Remove median for per-class stats to save space
                    stats_dict.pop('median', None)
                    stats['per_wsi_stats'][wsi_name][f'class_{class_id}'] = stats_dict
        
        # Global statistics
        all_scores_cat = torch.cat(all_scores, dim=0)
        if all_scores_cat.dim() == 1:
            stats['global_stats'] = {
                'total_patches': all_scores_cat.shape[0],
                'mean': all_scores_cat.mean().item(),
                'std': all_scores_cat.std().item(),
                'min': all_scores_cat.min().item(),
                'max': all_scores_cat.max().item(),
                'median': all_scores_cat.median().item(),
            }
        else:
            stats['global_stats']['total_patches'] = all_scores_cat.shape[0]
            for class_id in range(all_scores_cat.shape[1]):
                class_scores = all_scores_cat[:, class_id]
                stats['global_stats'][f'class_{class_id}'] = {
                    'mean': class_scores.mean().item(),
                    'std': class_scores.std().item(),
                    'min': class_scores.min().item(),
                    'max': class_scores.max().item(),
                }
        
        return stats


def create_loader_and_selector(cfg):
    """
    Convenience function to create PseudoLabelLoader and PatchSelector from config.
    
    Expected config keys:
    - pseudo_label_dir: Path to directory with .pt files
    - pseudo_label_binary_mode: Boolean, whether to use binary mode
    - pseudo_label_selection_strategy: Selection strategy name
    - pseudo_label_confidence_threshold: Default confidence threshold
    - num_classes: Number of classes
    
    Returns:
        (loader, selector) tuple
    """
    loader = PseudoLabelLoader(
        pseudo_label_dir=cfg.get('pseudo_label_dir'),
        binary_mode=cfg.get('pseudo_label_binary_mode', True),
        num_classes=cfg.get('num_classes', 2),
    )
    
    selector = PatchSelector(
        num_classes=cfg.get('num_classes', 2),
        selection_strategy=cfg.get('pseudo_label_selection_strategy', 'percentile'),
    )
    
    return loader, selector
